{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.scipy as jsp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate some dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "def generate(key, n, m):\n",
    "    x_0 = jax.random.normal(key, (n, n))\n",
    "    x_hist = jnp.zeros((m, n, n))\n",
    "\n",
    "    window = jax.random.normal(key, (n, n))\n",
    "\n",
    "    # diffuse the initial condition over time with random kernel\n",
    "    x = x_0\n",
    "    for i in range(m):\n",
    "        x = x + 0.1 * jsp.signal.correlate(x, window, mode='same')\n",
    "    \n",
    "        x_hist = x_hist.at[i, :].set(x)\n",
    "\n",
    "    # unsqueeze\n",
    "    x_hist = x_hist.reshape((m, n, n, 1))\n",
    "\n",
    "    return x_hist\n",
    "\n",
    "n = 10\n",
    "m = 50\n",
    "key = jax.random.PRNGKey(0)\n",
    "data = generate(key, n, m)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate 5 plots in a row\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(data[i], cmap='gray')\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clu import metrics\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax import struct\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = nn.Conv(features=32, kernel_size=(3, 3), strides=(2, 2))\n",
    "        self.conv2 = nn.Conv(features=64, kernel_size=(3, 3), strides=(2, 2))\n",
    "        self.conv3 = nn.Conv(features=128, kernel_size=(3, 3), strides=(2, 2))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'jaxlib.xla_extension.ArrayImpl' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m TrainState\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     14\u001b[0m       apply_fn\u001b[38;5;241m=\u001b[39mmodule\u001b[38;5;241m.\u001b[39mapply, params\u001b[38;5;241m=\u001b[39mparams, tx\u001b[38;5;241m=\u001b[39mtx,\n\u001b[1;32m     15\u001b[0m       metrics\u001b[38;5;241m=\u001b[39mMetrics\u001b[38;5;241m.\u001b[39mempty())\n\u001b[1;32m     17\u001b[0m state \u001b[38;5;241m=\u001b[39m create_train_state(Encoder(), jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/projects/msc-thesis/generator.env/lib/python3.10/site-packages/flax/core/scope.py:1199\u001b[0m, in \u001b[0;36m_is_valid_variables\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_valid_variables\u001b[39m(variables: VariableDict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether the given variable dict is valid.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;124;03m    True if `variables` is a valid variable dict.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1201\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "  accuracy: metrics.Accuracy\n",
    "  loss: metrics.Average.from_output('loss')\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "  metrics: Metrics\n",
    "\n",
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  params = module.init(rng, jnp.ones([n, n, 1]))['params'] # initialize parameters by passing a template image\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "\n",
    "state = create_train_state(Encoder(), jax.random.PRNGKey(0), 1e-3, 0.9)\n",
    "\n",
    "print(state.apply_fn(data[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    logits = state.apply_fn({'params': params}, batch['image'])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch['label']).mean()\n",
    "    return loss\n",
    "  grad_fn = jax.grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        return\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    },
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Initializer expected to generate shape (3, 3, 1, 32) but got shape (3, 3, 10, 32) instead for parameter \"kernel\" in \"/conv1\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m params \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39minit(key, jnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoded\u001b[38;5;241m.\u001b[39mshape)\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[62], line 9\u001b[0m, in \u001b[0;36mEncoder.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/projects/msc-thesis/generator.env/lib/python3.10/site-packages/flax/linen/linear.py:637\u001b[0m, in \u001b[0;36m_Conv.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m kernel_shape:\n\u001b[1;32m    632\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask needs to have the same shape as weights. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShapes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    635\u001b[0m   )\n\u001b[0;32m--> 637\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m   kernel \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/projects/msc-thesis/generator.env/lib/python3.10/site-packages/flax/core/scope.py:982\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 982\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(\n\u001b[1;32m    983\u001b[0m         name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text, jnp\u001b[38;5;241m.\u001b[39mshape(abs_val), jnp\u001b[38;5;241m.\u001b[39mshape(val)\n\u001b[1;32m    984\u001b[0m       )\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Initializer expected to generate shape (3, 3, 1, 32) but got shape (3, 3, 10, 32) instead for parameter \"kernel\" in \"/conv1\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = nn.Conv(features=32, kernel_size=(3, 3), strides=(2, 2))\n",
    "        self.conv2 = nn.Conv(features=64, kernel_size=(3, 3), strides=(2, 2))\n",
    "        self.conv3 = nn.Conv(features=128, kernel_size=(3, 3), strides=(2, 2))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "encoder = Encoder()\n",
    "params = encoder.init(key, jnp.ones((10, 10, 10, 1)))\n",
    "\n",
    "print(data[0].shape)\n",
    "encoded = encoder.apply(params, data[0])\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        return\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generator.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
